// Multithreaded benchmark using Rayon for parallel processing

use log_analyzer::log_matcher::{LogMatcher, LogTemplate};
use rayon::prelude::*;
use std::sync::Arc;
use std::time::Instant;

/// Generate a variety of mock log entries for testing
fn generate_mock_logs(count: usize) -> Vec<String> {
    let mut logs = Vec::with_capacity(count);

    let patterns = vec![
        (
            "cpu_usage: {:.1}% - Server load {}",
            vec!["normal", "high", "critical", "moderate"],
        ),
        (
            "memory_usage: {:.1}GB - Memory consumption {}",
            vec!["stable", "increasing", "high", "normal"],
        ),
        (
            "disk_io: {}MB/s - Disk activity {}",
            vec!["low", "moderate", "high", "normal"],
        ),
        (
            "network_traffic: {}Mbps - Network load {}",
            vec!["light", "moderate", "heavy", "normal"],
        ),
        (
            "error_rate: {:.2}% - System status {}",
            vec!["healthy", "degraded", "critical", "recovering"],
        ),
        (
            "request_latency: {}ms - Response time {}",
            vec!["optimal", "acceptable", "slow", "fast"],
        ),
        (
            "database_connections: {} - Pool status {}",
            vec!["available", "limited", "exhausted", "healthy"],
        ),
    ];

    for i in 0..count {
        let pattern_idx = i % patterns.len();
        let (_template, variants) = &patterns[pattern_idx];

        let log = match pattern_idx {
            0 => {
                let value = 10.0 + (i % 90) as f64;
                let variant = variants[i % variants.len()];
                format!("cpu_usage: {:.1}% - Server load {}", value, variant)
            }
            1 => {
                let value = 0.5 + (i % 30) as f64 * 0.1;
                let variant = variants[i % variants.len()];
                format!(
                    "memory_usage: {:.1}GB - Memory consumption {}",
                    value, variant
                )
            }
            2 => {
                let value = 10 + (i % 500);
                let variant = variants[i % variants.len()];
                format!("disk_io: {}MB/s - Disk activity {}", value, variant)
            }
            3 => {
                let value = 1 + (i % 1000);
                let variant = variants[i % variants.len()];
                format!("network_traffic: {}Mbps - Network load {}", value, variant)
            }
            4 => {
                let value = (i % 100) as f64 * 0.01;
                let variant = variants[i % variants.len()];
                format!("error_rate: {:.2}% - System status {}", value, variant)
            }
            5 => {
                let value = 10 + (i % 500);
                let variant = variants[i % variants.len()];
                format!("request_latency: {}ms - Response time {}", value, variant)
            }
            6 => {
                let value = 1 + (i % 100);
                let variant = variants[i % variants.len()];
                format!("database_connections: {} - Pool status {}", value, variant)
            }
            _ => unreachable!(),
        };

        logs.push(log);
    }

    logs
}

/// Setup matcher with templates
fn setup_matcher_with_templates() -> Arc<LogMatcher> {
    let mut matcher = LogMatcher::new();

    let templates = vec![
        LogTemplate {
            template_id: 0,
            pattern: r"network_traffic: (\d+)Mbps - Network load (.*)".to_string(),
            variables: vec!["throughput".to_string(), "status".to_string()],
            example: "network_traffic: 500Mbps - Network load moderate".to_string(),
        },
        LogTemplate {
            template_id: 0,
            pattern: r"error_rate: (\d+\.\d+)% - System status (.*)".to_string(),
            variables: vec!["rate".to_string(), "status".to_string()],
            example: "error_rate: 0.05% - System status healthy".to_string(),
        },
        LogTemplate {
            template_id: 0,
            pattern: r"request_latency: (\d+)ms - Response time (.*)".to_string(),
            variables: vec!["latency".to_string(), "status".to_string()],
            example: "request_latency: 125ms - Response time acceptable".to_string(),
        },
        LogTemplate {
            template_id: 0,
            pattern: r"database_connections: (\d+) - Pool status (.*)".to_string(),
            variables: vec!["count".to_string(), "status".to_string()],
            example: "database_connections: 45 - Pool status healthy".to_string(),
        },
    ];

    for template in templates {
        matcher.add_template(template);
    }

    Arc::new(matcher)
}

/// Run benchmark with specified thread count
fn run_parallel_benchmark(name: &str, log_count: usize, thread_count: Option<usize>) {
    // Set thread pool size if specified
    if let Some(threads) = thread_count {
        rayon::ThreadPoolBuilder::new()
            .num_threads(threads)
            .build_global()
            .ok();
    }

    let actual_threads = rayon::current_num_threads();

    println!("\n{}", "=".repeat(60));
    println!("ğŸ“Š Benchmark (Parallel): {}", name);
    println!("   Threads: {}", actual_threads);
    println!("{}", "=".repeat(60));

    // Setup
    println!("âš™ï¸  Setting up matcher with templates...");
    let matcher = setup_matcher_with_templates();
    let template_count = matcher.get_all_templates().len();
    println!("   âœ“ {} templates loaded", template_count);
    println!("   âœ“ Arc<RwLock<>> for thread-safe reads");

    // Generate logs
    println!("ğŸ“ Generating {} mock logs...", log_count);
    let start = Instant::now();
    let logs = generate_mock_logs(log_count);
    let gen_duration = start.elapsed();
    println!(
        "   âœ“ Generated in {:.2}ms",
        gen_duration.as_secs_f64() * 1000.0
    );

    // Process logs in parallel
    println!("ğŸ” Processing logs through radix trie (parallel)...");
    let start = Instant::now();

    let results: Vec<_> = logs.par_iter().map(|log| matcher.match_log(log)).collect();

    let duration = start.elapsed();

    // Calculate statistics
    let matched = results.iter().filter(|r| r.matched).count();
    let unmatched = results.len() - matched;
    let total_extracted_values: usize = results.iter().map(|r| r.extracted_values.len()).sum();

    // Calculate metrics
    let total_ms = duration.as_secs_f64() * 1000.0;
    let logs_per_second = log_count as f64 / duration.as_secs_f64();
    let avg_latency_us = (duration.as_micros() as f64) / log_count as f64;

    // Print results
    println!("\nğŸ“ˆ Results:");
    println!("   Total logs processed:  {}", log_count);
    println!(
        "   Matched:               {} ({:.1}%)",
        matched,
        (matched as f64 / log_count as f64) * 100.0
    );
    println!(
        "   Unmatched:             {} ({:.1}%)",
        unmatched,
        (unmatched as f64 / log_count as f64) * 100.0
    );
    println!("   Extracted values:      {}", total_extracted_values);
    println!("\nâš¡ Performance:");
    println!("   Total time:            {:.2}ms", total_ms);
    println!("   Throughput:            {:.0} logs/sec", logs_per_second);
    println!("   Avg latency:           {:.2}Î¼s per log", avg_latency_us);
    println!(
        "   Per-thread throughput: {:.0} logs/sec",
        logs_per_second / actual_threads as f64
    );

    if total_ms > 1.0 {
        println!("\nğŸ’¾ Memory efficiency:");
        println!("   Templates:             {}", template_count);
        println!("   Threads:               {}", actual_threads);
        println!(
            "   Avg matches/template:  {:.0}",
            matched as f64 / template_count as f64
        );
    }
}

#[test]
fn benchmark_parallel_1_thread() {
    run_parallel_benchmark("10K logs, 1 thread", 10_000, Some(1));
}

#[test]
fn benchmark_parallel_2_threads() {
    run_parallel_benchmark("10K logs, 2 threads", 10_000, Some(2));
}

#[test]
fn benchmark_parallel_4_threads() {
    run_parallel_benchmark("10K logs, 4 threads", 10_000, Some(4));
}

#[test]
fn benchmark_parallel_8_threads() {
    run_parallel_benchmark("10K logs, 8 threads", 10_000, Some(8));
}

#[test]
fn benchmark_parallel_default() {
    run_parallel_benchmark("10K logs, default threads", 10_000, None);
}

#[test]
fn benchmark_parallel_100k() {
    run_parallel_benchmark("100K logs, default threads", 100_000, None);
}

#[test]
fn benchmark_parallel_1m() {
    run_parallel_benchmark("1M logs, default threads", 1_000_000, None);
}

#[test]
fn benchmark_parallel_scaling() {
    println!("\n{}", "â–ˆ".repeat(60));
    println!("ğŸš€ PARALLEL SCALING BENCHMARK");
    println!("   Testing throughput scaling with multiple threads");
    println!("{}\n", "â–ˆ".repeat(60));

    let log_count = 100_000;

    for threads in [1, 2, 4, 8] {
        run_parallel_benchmark(
            &format!("100K logs, {} thread(s)", threads),
            log_count,
            Some(threads),
        );
        println!();
    }

    println!("{}", "â–ˆ".repeat(60));
    println!("âœ… Parallel scaling benchmark completed!");
    println!("{}", "â–ˆ".repeat(60));
}
