// Benchmark for structural sharing (lock-free reads and writes)

mod structural_sharing_matcher;
use rayon::prelude::*;
use std::sync::Arc;
use std::time::Instant;
use structural_sharing_matcher::{LogTemplate, StructuralSharingMatcher};

fn generate_mock_logs(count: usize) -> Vec<String> {
    let mut logs = Vec::with_capacity(count);

    let patterns = vec![
        (
            "cpu_usage: {:.1}% - Server load {}",
            vec!["normal", "high", "critical", "moderate"],
        ),
        (
            "memory_usage: {:.1}GB - Memory consumption {}",
            vec!["stable", "increasing", "high", "normal"],
        ),
        (
            "disk_io: {}MB/s - Disk activity {}",
            vec!["low", "moderate", "high", "normal"],
        ),
        (
            "network_traffic: {}Mbps - Network load {}",
            vec!["light", "moderate", "heavy", "normal"],
        ),
        (
            "error_rate: {:.2}% - System status {}",
            vec!["healthy", "degraded", "critical", "recovering"],
        ),
        (
            "request_latency: {}ms - Response time {}",
            vec!["optimal", "acceptable", "slow", "fast"],
        ),
        (
            "database_connections: {} - Pool status {}",
            vec!["available", "limited", "exhausted", "healthy"],
        ),
    ];

    for i in 0..count {
        let pattern_idx = i % patterns.len();
        let (_template, variants) = &patterns[pattern_idx];

        let log = match pattern_idx {
            0 => {
                let value = 10.0 + (i % 90) as f64;
                let variant = variants[i % variants.len()];
                format!("cpu_usage: {:.1}% - Server load {}", value, variant)
            }
            1 => {
                let value = 0.5 + (i % 30) as f64 * 0.1;
                let variant = variants[i % variants.len()];
                format!(
                    "memory_usage: {:.1}GB - Memory consumption {}",
                    value, variant
                )
            }
            2 => {
                let value = 10 + (i % 500);
                let variant = variants[i % variants.len()];
                format!("disk_io: {}MB/s - Disk activity {}", value, variant)
            }
            3 => {
                let value = 1 + (i % 1000);
                let variant = variants[i % variants.len()];
                format!("network_traffic: {}Mbps - Network load {}", value, variant)
            }
            4 => {
                let value = (i % 100) as f64 * 0.01;
                let variant = variants[i % variants.len()];
                format!("error_rate: {:.2}% - System status {}", value, variant)
            }
            5 => {
                let value = 10 + (i % 500);
                let variant = variants[i % variants.len()];
                format!("request_latency: {}ms - Response time {}", value, variant)
            }
            6 => {
                let value = 1 + (i % 100);
                let variant = variants[i % variants.len()];
                format!("database_connections: {} - Pool status {}", value, variant)
            }
            _ => unreachable!(),
        };

        logs.push(log);
    }

    logs
}

fn setup_matcher() -> Arc<StructuralSharingMatcher> {
    let matcher = StructuralSharingMatcher::new();

    let templates = vec![
        LogTemplate {
            template_id: 4,
            pattern: r"network_traffic: (\d+)Mbps - Network load (.*)".to_string(),
            variables: vec!["throughput".to_string(), "status".to_string()],
            example: "network_traffic: 500Mbps - Network load moderate".to_string(),
        },
        LogTemplate {
            template_id: 5,
            pattern: r"error_rate: (\d+\.\d+)% - System status (.*)".to_string(),
            variables: vec!["rate".to_string(), "status".to_string()],
            example: "error_rate: 0.05% - System status healthy".to_string(),
        },
        LogTemplate {
            template_id: 6,
            pattern: r"request_latency: (\d+)ms - Response time (.*)".to_string(),
            variables: vec!["latency".to_string(), "status".to_string()],
            example: "request_latency: 125ms - Response time acceptable".to_string(),
        },
        LogTemplate {
            template_id: 7,
            pattern: r"database_connections: (\d+) - Pool status (.*)".to_string(),
            variables: vec!["count".to_string(), "status".to_string()],
            example: "database_connections: 45 - Pool status healthy".to_string(),
        },
    ];

    for template in templates {
        matcher.add_template(template);
    }

    Arc::new(matcher)
}

fn run_benchmark(name: &str, log_count: usize, thread_count: Option<usize>) {
    if let Some(threads) = thread_count {
        rayon::ThreadPoolBuilder::new()
            .num_threads(threads)
            .build_global()
            .ok();
    }

    let actual_threads = rayon::current_num_threads();

    println!("\n{}", "=".repeat(60));
    println!("ğŸ“Š Benchmark (Structural Sharing): {}", name);
    println!("   Threads: {}", actual_threads);
    println!("{}", "=".repeat(60));

    println!("âš™ï¸  Setting up structural sharing matcher...");
    let matcher = setup_matcher();
    let template_count = matcher.get_all_templates().len();
    println!("   âœ“ {} templates loaded", template_count);
    println!("   âœ“ Using ArcSwap + im::HashMap (structural sharing)");
    println!("   âœ“ Lock-free reads, CoW writes");

    println!("ğŸ“ Generating {} mock logs...", log_count);
    let start = Instant::now();
    let logs = generate_mock_logs(log_count);
    let gen_duration = start.elapsed();
    println!(
        "   âœ“ Generated in {:.2}ms",
        gen_duration.as_secs_f64() * 1000.0
    );

    println!("ğŸ” Processing logs (lock-free parallel reads)...");
    let start = Instant::now();

    let results: Vec<_> = logs.par_iter().map(|log| matcher.match_log(log)).collect();

    let duration = start.elapsed();

    let matched = results.iter().filter(|r| r.matched).count();
    let unmatched = results.len() - matched;
    let total_extracted_values: usize = results.iter().map(|r| r.extracted_values.len()).sum();

    let total_ms = duration.as_secs_f64() * 1000.0;
    let logs_per_second = log_count as f64 / duration.as_secs_f64();
    let avg_latency_us = (duration.as_micros() as f64) / log_count as f64;

    println!("\nğŸ“ˆ Results:");
    println!("   Total logs processed:  {}", log_count);
    println!(
        "   Matched:               {} ({:.1}%)",
        matched,
        (matched as f64 / log_count as f64) * 100.0
    );
    println!(
        "   Unmatched:             {} ({:.1}%)",
        unmatched,
        (unmatched as f64 / log_count as f64) * 100.0
    );
    println!("   Extracted values:      {}", total_extracted_values);
    println!("\nâš¡ Performance:");
    println!("   Total time:            {:.2}ms", total_ms);
    println!("   Throughput:            {:.0} logs/sec", logs_per_second);
    println!("   Avg latency:           {:.2}Î¼s per log", avg_latency_us);
    println!(
        "   Per-thread throughput: {:.0} logs/sec",
        logs_per_second / actual_threads as f64
    );
    println!("   Speedup vs 1 thread:   {:.2}x", logs_per_second / 7800.0);

    if total_ms > 1.0 {
        println!("\nğŸ’¾ Structural Sharing Benefits:");
        println!("   âœ“ Zero lock contention on reads");
        println!("   âœ“ Readers never blocked by writers");
        println!("   âœ“ Memory-efficient (shared structure)");
        println!("   Templates:             {}", template_count);
        println!("   Threads:               {}", actual_threads);
        println!(
            "   Parallel efficiency:   {:.1}%",
            (logs_per_second / (7800.0 * actual_threads as f64)) * 100.0
        );
    }
}

#[test]
fn benchmark_structural_1_thread() {
    run_benchmark("10K logs, 1 thread", 10_000, Some(1));
}

#[test]
fn benchmark_structural_2_threads() {
    run_benchmark("10K logs, 2 threads", 10_000, Some(2));
}

#[test]
fn benchmark_structural_4_threads() {
    run_benchmark("10K logs, 4 threads", 10_000, Some(4));
}

#[test]
fn benchmark_structural_8_threads() {
    run_benchmark("10K logs, 8 threads", 10_000, Some(8));
}

#[test]
fn benchmark_structural_100k() {
    run_benchmark("100K logs, default threads", 100_000, None);
}

#[test]
fn benchmark_structural_1m() {
    run_benchmark("1M logs, default threads", 1_000_000, None);
}

#[test]
fn benchmark_structural_scaling() {
    println!("\n{}", "â–ˆ".repeat(60));
    println!("ğŸ”„ STRUCTURAL SHARING SCALING BENCHMARK");
    println!("   Lock-free reads + CoW writes");
    println!("{}\n", "â–ˆ".repeat(60));

    let log_count = 100_000;

    for threads in [1, 2, 4, 8] {
        run_benchmark(
            &format!("100K logs, {} thread(s)", threads),
            log_count,
            Some(threads),
        );
        println!();
    }

    println!("{}", "â–ˆ".repeat(60));
    println!("âœ… Structural sharing scaling completed!");
    println!("   Near-linear scaling with zero lock contention!");
    println!("{}", "â–ˆ".repeat(60));
}

#[test]
fn benchmark_concurrent_reads_and_writes() {
    use std::sync::atomic::{AtomicUsize, Ordering};
    use std::thread;

    println!("\n{}", "=".repeat(60));
    println!("ğŸ”€ Concurrent Reads + Writes Benchmark");
    println!("{}", "=".repeat(60));

    let matcher = setup_matcher();
    let logs = generate_mock_logs(10_000);
    let matched_count = Arc::new(AtomicUsize::new(0));

    println!("âš™ï¸  Starting 4 reader threads + 1 writer thread...");
    let start = Instant::now();

    let mut handles = vec![];

    // 4 reader threads
    for _ in 0..4 {
        let m = Arc::clone(&matcher);
        let logs_clone = logs.clone();
        let count = Arc::clone(&matched_count);

        handles.push(thread::spawn(move || {
            for log in &logs_clone {
                let result = m.match_log(log);
                if result.matched {
                    count.fetch_add(1, Ordering::Relaxed);
                }
            }
        }));
    }

    // 1 writer thread adding templates
    let m = Arc::clone(&matcher);
    handles.push(thread::spawn(move || {
        for i in 0..100 {
            m.add_template(LogTemplate {
                template_id: 100 + i,
                pattern: format!(r"new_pattern_{}: (\d+)", i),
                variables: vec!["value".to_string()],
                example: format!("new_pattern_{}: 123", i),
            });
            thread::sleep(std::time::Duration::from_micros(100));
        }
    }));

    for handle in handles {
        handle.join().unwrap();
    }

    let duration = start.elapsed();
    let total_reads = 10_000 * 4;
    let reads_per_second = total_reads as f64 / duration.as_secs_f64();

    println!("\nğŸ“ˆ Results:");
    println!("   Total reads:           {}", total_reads);
    println!("   Total writes:          100 templates");
    println!(
        "   Matched logs:          {}",
        matched_count.load(Ordering::Relaxed)
    );
    println!(
        "   Duration:              {:.2}ms",
        duration.as_secs_f64() * 1000.0
    );
    println!(
        "   Read throughput:       {:.0} reads/sec",
        reads_per_second
    );
    println!("\nâœ… Readers never blocked by writer!");
    println!("   This is the power of structural sharing!");
}
